{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42398</th>\n",
       "      <td>Terence Stamp can carry off anything, but this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32208</th>\n",
       "      <td>Three zany couples, all SIX OF A KIND, become ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42767</th>\n",
       "      <td>When my 14-year-old daughter and her friends g...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34757</th>\n",
       "      <td>The humor is non-existent in this loser of a m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40161</th>\n",
       "      <td>I am pretty surprised to see that this movie e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>This was a truly insipid film. The performance...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47137</th>\n",
       "      <td>There's plenty to appreciate here: spectacular...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38200</th>\n",
       "      <td>Eddie Fischer was simply bad. Possibly the wor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>A young Frenchman uproots himself as he become...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>Police, investigations, murder, suspicion: we ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "42398  Terence Stamp can carry off anything, but this...  negative\n",
       "32208  Three zany couples, all SIX OF A KIND, become ...  positive\n",
       "42767  When my 14-year-old daughter and her friends g...  positive\n",
       "34757  The humor is non-existent in this loser of a m...  negative\n",
       "40161  I am pretty surprised to see that this movie e...  negative\n",
       "21669  This was a truly insipid film. The performance...  negative\n",
       "47137  There's plenty to appreciate here: spectacular...  negative\n",
       "38200  Eddie Fischer was simply bad. Possibly the wor...  negative\n",
       "28775  A young Frenchman uproots himself as he become...  positive\n",
       "16277  Police, investigations, murder, suspicion: we ...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_imdb=pd.read_csv('./Datasets/IMDB_Dataset_cleaned.csv')\n",
    "df_imdb.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_imdb=pd.read_csv('./Datasets/IMDB Dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ajf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ajf/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "\n",
    "# Initialize tokenizer, lemmatizer, and stemmer\n",
    "tokenizer = word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "pattern = r'\\s{2,}'\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text=re.sub(r'<[^>]*>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s\\'.?!,:;-]', '', text)\n",
    "    text = re.sub(r'([^\\w\\s]|_)(?=\\1)', '', text)\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # Tokenize text\n",
    "    tokens = tokenizer(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Stem tokens\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "    return text\n",
    "\n",
    "df_imdb['cleaned_text'] = df_imdb['review'].apply(preprocess_text)\n",
    "df_imdb.to_csv('./Datasets/IMDB Dataset_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer:\n",
      "Accuracy: 0.8588666666666667\n",
      "Precision: 0.8593527190443919\n",
      "Recall: 0.8588666666666667\n",
      "F1 Score: 0.8588535070109312\n",
      "\n",
      "TfidfVectorizer:\n",
      "Accuracy: 0.8534\n",
      "Precision: 0.8539029449817557\n",
      "Recall: 0.8534\n",
      "F1 Score: 0.8533849778813225\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "label_encoder = LabelEncoder()\n",
    "df_imdb['sentiment'] = label_encoder.fit_transform(df_imdb['sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imdb['cleaned_text'], df_imdb['sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define pipelines\n",
    "count_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data (CountVectorizer)\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data (CountVectorizer)\n",
    "y_pred_count = tfidf_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (CountVectorizer)\n",
    "accuracy_count = accuracy_score(y_test, y_pred_count)\n",
    "precision_count = precision_score(y_test, y_pred_count, average='weighted')\n",
    "recall_count = recall_score(y_test, y_pred_count, average='weighted')\n",
    "f1_count = f1_score(y_test, y_pred_count, average='weighted')\n",
    "\n",
    "# Fit the classifier to the training data (TfidfVectorizer)\n",
    "count_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data (TfidfVectorizer)\n",
    "y_pred_tfidf = count_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (TfidfVectorizer)\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "precision_tfidf = precision_score(y_test, y_pred_tfidf, average='weighted')\n",
    "recall_tfidf = recall_score(y_test, y_pred_tfidf, average='weighted')\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf, average='weighted')\n",
    "\n",
    "# Compare the performance of models\n",
    "print(\"CountVectorizer:\")\n",
    "print(\"Accuracy:\", accuracy_count)\n",
    "print(\"Precision:\", precision_count)\n",
    "print(\"Recall:\", recall_count)\n",
    "print(\"F1 Score:\", f1_count)\n",
    "\n",
    "print(\"\\nTfidfVectorizer:\")\n",
    "print(\"Accuracy:\", accuracy_tfidf)\n",
    "print(\"Precision:\", precision_tfidf)\n",
    "print(\"Recall:\", recall_tfidf)\n",
    "print(\"F1 Score:\", f1_tfidf)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(tfidf_pipeline, 'tfidf_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8611\n",
      "accuracy Standard Deviation: 0.0042\n",
      "Average precision: 0.8696\n",
      "precision Standard Deviation: 0.0083\n",
      "Average recall: 0.8495\n",
      "recall Standard Deviation: 0.0082\n",
      "Average f1: 0.8594\n",
      "f1 Standard Deviation: 0.0045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Store the scores for each metric\n",
    "scores = {metric: cross_val_score(tfidf_pipeline, df_imdb['cleaned_text'], df_imdb['sentiment'], cv=kf, scoring=metric) for metric in scoring}\n",
    "\n",
    "# Compute average and standard deviation for each metric\n",
    "avg_scores = {metric: np.mean(scores[metric]) for metric in scoring}\n",
    "std_scores = {metric: np.std(scores[metric]) for metric in scoring}\n",
    "\n",
    "# Print results\n",
    "for metric in scoring:\n",
    "    print(\"Average {}: {:.4f}\".format(metric, avg_scores[metric]))\n",
    "    print(\"{} Standard Deviation: {:.4f}\".format(metric, std_scores[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8551\n",
      "accuracy Standard Deviation: 0.0037\n",
      "Average precision: 0.8692\n",
      "precision Standard Deviation: 0.0069\n",
      "Average recall: 0.8360\n",
      "recall Standard Deviation: 0.0059\n",
      "Average f1: 0.8522\n",
      "f1 Standard Deviation: 0.0038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Store the scores for each metric\n",
    "scores = {metric: cross_val_score(count_pipeline, df_imdb['cleaned_text'], df_imdb['sentiment'], cv=kf, scoring=metric) for metric in scoring}\n",
    "\n",
    "# Compute average and standard deviation for each metric\n",
    "avg_scores = {metric: np.mean(scores[metric]) for metric in scoring}\n",
    "std_scores = {metric: np.std(scores[metric]) for metric in scoring}\n",
    "\n",
    "# Print results\n",
    "for metric in scoring:\n",
    "    print(\"Average {}: {:.4f}\".format(metric, avg_scores[metric]))\n",
    "    print(\"{} Standard Deviation: {:.4f}\".format(metric, std_scores[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "a=joblib.load('tfidf_pipeline.joblib')\n",
    "predicted_sentiment = []\n",
    "challenging_comments = [\n",
    "    \"I love it\",\n",
    "    \"This movie was absolutely terrible. I couldn't stand it.\",\n",
    "    \"I thought this film would be good, but it turned out to be a disappointment.\",\n",
    "    \"The acting was mediocre, and the plot was predictable.\",\n",
    "    \"I wasn't expecting much from this movie, but it exceeded my expectations.\",\n",
    "    \"The cinematography was stunning, but the storyline fell flat.\",\n",
    "    \"I found the characters unlikable, and the dialogue was cringeworthy.\",\n",
    "    \"Despite its flaws, I found myself thoroughly entertained by this film.\",\n",
    "    \"This movie was a waste of time. I regret watching it.\",\n",
    "    \"The pacing was off, and the editing was choppy.\",\n",
    "    \"I was pleasantly surprised by how much I enjoyed this film.\"\n",
    "]\n",
    "for comment in challenging_comments:\n",
    "    temp=label_encoder.inverse_transform(a.predict([comment]))\n",
    "    print(temp)\n",
    "    predicted_sentiment.append(temp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
