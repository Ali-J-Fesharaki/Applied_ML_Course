{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_pregnant_no</th>\n",
       "      <th>plasma_concentration</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>triceps_skinfold_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_pregnant_no  plasma_concentration  diastolic_blood_pressure  \\\n",
       "0                 6                   148                        72   \n",
       "1                 1                    85                        66   \n",
       "2                 8                   183                        64   \n",
       "3                 1                    89                        66   \n",
       "4                 0                   137                        40   \n",
       "\n",
       "   triceps_skinfold_thickness  serum_insulin   bmi  diabetes_pedigree  age  \\\n",
       "0                          35              0  33.6              0.627   50   \n",
       "1                          29              0  26.6              0.351   31   \n",
       "2                           0              0  23.3              0.672   32   \n",
       "3                          23             94  28.1              0.167   21   \n",
       "4                          35            168  43.1              2.288   33   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the dataset\n",
    "df = pd.read_csv('pima_indians_diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_zeros = ['plasma_concentration', 'diastolic_blood_pressure', 'triceps_skinfold_thickness', \n",
    "                      'serum_insulin', 'bmi']\n",
    "df[columns_with_zeros] = df[columns_with_zeros].replace(0, np.nan)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[columns_with_zeros] = imputer.fit_transform(df[columns_with_zeros])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = df.drop(columns=['class'])\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Combine scaled features with the target variable\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "df_scaled['class'] = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_scaled=df_scaled.drop(columns='class')\n",
    "y=df_scaled['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, max_features: sqrt, max_depth: 15,accuracy: 0.7551435406698563, precision: 0.6727917396613049, recall: 0.5727906561777529, f1_score: 0.6160042624976325\n",
      "n_estimators: 10, max_features: sqrt, max_depth: 15,accuracy: 0.7551435406698563, precision: 0.6727917396613049, recall: 0.5727906561777529, f1_score: 0.6160042624976325\n",
      "n_estimators: 10, max_features: sqrt, max_depth: 20,accuracy: 0.7538619275461381, precision: 0.6817583492022853, recall: 0.5482875296746265, f1_score: 0.605146055561536\n",
      "n_estimators: 10, max_features: log2, max_depth: 15,accuracy: 0.7434381408065618, precision: 0.6549095975275648, recall: 0.542762758149855, f1_score: 0.5873461200409931\n",
      "n_estimators: 10, max_features: log2, max_depth: 15,accuracy: 0.7434381408065618, precision: 0.6549095975275648, recall: 0.542762758149855, f1_score: 0.5873461200409931\n",
      "n_estimators: 10, max_features: log2, max_depth: 20,accuracy: 0.7421394395078605, precision: 0.6590078279252509, recall: 0.5360130490775652, f1_score: 0.5856262162212348\n",
      "n_estimators: 10, max_features: None, max_depth: 15,accuracy: 0.7409261790840739, precision: 0.6546465692117865, recall: 0.5294017440146472, f1_score: 0.5832782557782558\n",
      "n_estimators: 10, max_features: None, max_depth: 15,accuracy: 0.7409261790840739, precision: 0.6546465692117865, recall: 0.5294017440146472, f1_score: 0.5832782557782558\n",
      "n_estimators: 10, max_features: None, max_depth: 20,accuracy: 0.7396445659603554, precision: 0.6517229437229437, recall: 0.5242461170848267, f1_score: 0.5790501165501165\n",
      "n_estimators: 15, max_features: sqrt, max_depth: 15,accuracy: 0.7591079972658921, precision: 0.6722176979691972, recall: 0.6107855823984857, f1_score: 0.6358605410816364\n",
      "n_estimators: 15, max_features: sqrt, max_depth: 15,accuracy: 0.7591079972658921, precision: 0.6722176979691972, recall: 0.6107855823984857, f1_score: 0.6358605410816364\n",
      "n_estimators: 15, max_features: sqrt, max_depth: 20,accuracy: 0.7630382775119617, precision: 0.6740031635031635, recall: 0.6140979689366787, f1_score: 0.639811587146844\n",
      "n_estimators: 15, max_features: log2, max_depth: 15,accuracy: 0.7590738209159262, precision: 0.6724488844488845, recall: 0.5995332743719841, f1_score: 0.6287199562649981\n",
      "n_estimators: 15, max_features: log2, max_depth: 15,accuracy: 0.7590738209159262, precision: 0.6724488844488845, recall: 0.5995332743719841, f1_score: 0.6287199562649981\n",
      "n_estimators: 15, max_features: log2, max_depth: 20,accuracy: 0.7629528366370472, precision: 0.6743732397956033, recall: 0.6225207683594781, f1_score: 0.6423549163479642\n",
      "n_estimators: 15, max_features: None, max_depth: 15,accuracy: 0.7448051948051948, precision: 0.6538011626055104, recall: 0.5754301230430262, f1_score: 0.6088876120018125\n",
      "n_estimators: 15, max_features: None, max_depth: 15,accuracy: 0.7448051948051948, precision: 0.6538011626055104, recall: 0.5754301230430262, f1_score: 0.6088876120018125\n",
      "n_estimators: 15, max_features: None, max_depth: 20,accuracy: 0.7435235816814765, precision: 0.649322327084321, recall: 0.5739781998169096, f1_score: 0.605977539618056\n",
      "n_estimators: 20, max_features: sqrt, max_depth: 15,accuracy: 0.7564593301435407, precision: 0.6702158127285563, recall: 0.5938188179801083, f1_score: 0.6259014230096591\n",
      "n_estimators: 20, max_features: sqrt, max_depth: 15,accuracy: 0.7564593301435407, precision: 0.6702158127285563, recall: 0.5938188179801083, f1_score: 0.6259014230096591\n",
      "n_estimators: 20, max_features: sqrt, max_depth: 20,accuracy: 0.7577751196172249, precision: 0.679891891733997, recall: 0.5798743968098806, f1_score: 0.6211530458161186\n",
      "n_estimators: 20, max_features: log2, max_depth: 15,accuracy: 0.7525803144224198, precision: 0.6739434225195096, recall: 0.5672458533103695, f1_score: 0.608135535004027\n",
      "n_estimators: 20, max_features: log2, max_depth: 15,accuracy: 0.7525803144224198, precision: 0.6739434225195096, recall: 0.5672458533103695, f1_score: 0.608135535004027\n",
      "n_estimators: 20, max_features: log2, max_depth: 20,accuracy: 0.7551777170198224, precision: 0.6790143124139287, recall: 0.5729984018371115, f1_score: 0.6156382288194894\n",
      "n_estimators: 20, max_features: None, max_depth: 15,accuracy: 0.7525974025974026, precision: 0.6684045995209678, recall: 0.5857615323744356, f1_score: 0.6215120571699518\n",
      "n_estimators: 20, max_features: None, max_depth: 15,accuracy: 0.7525974025974026, precision: 0.6684045995209678, recall: 0.5857615323744356, f1_score: 0.6215120571699518\n",
      "n_estimators: 20, max_features: None, max_depth: 20,accuracy: 0.7525974025974026, precision: 0.6711587126604763, recall: 0.5820578286707319, f1_score: 0.6206724581724581\n",
      "0.6423549163479642 {'n_estimators': 15, 'max_features': 'log2', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score , precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "n_estimators_options = [10, 15, 20]\n",
    "max_features_options = [ 'sqrt', 'log2',None]\n",
    "max_depth_options = [15, 15, 20]\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_val_score_rf(X, y, n_estimators, max_features, max_depth, cv=10):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        precisions.append(precision_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    \n",
    "    return [np.mean(accuracies), np.mean(precisions), np.mean(recalls), np.mean(f1_scores) ]\n",
    "\n",
    "# Perform cross-validation for each combination of parameters\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_estimators in n_estimators_options:\n",
    "    for max_features in max_features_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            temp_accuracies,temp_precisions,temp_recalls,temp_f1_scores = cross_val_score_rf(X_scaled, y, n_estimators, max_features, max_depth, cv=10)\n",
    "            print(f'n_estimators: {n_estimators}, max_features: {max_features}, max_depth: {max_depth},accuracy: {temp_accuracies}, precision: {temp_precisions}, recall: {temp_recalls}, f1_score: {temp_f1_scores}')\n",
    "            if temp_f1_scores > best_score:\n",
    "                best_score = temp_f1_scores\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "\n",
    "                }\n",
    "\n",
    "print(best_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ajf/Share/PhD_Mechatronics/semester_2/ML_Applied/HomeWork/Applied_ML_Course/ML-HW02/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Models Accuracies: {'Gradient Boosting': 0.7603212576896787, 'AdaBoost': 0.753879015721121, 'XGBoost': 0.7473513328776487}\n",
      "Ensemble Models Precisions: {'Gradient Boosting': 0.6769140630412, 'AdaBoost': 0.6620417780217558, 'XGBoost': 0.6579206669289789} \n",
      "Ensemble Models Recalls: {'Gradient Boosting': 0.6203810609939643, 'AdaBoost': 0.5978312774441806, 'XGBoost': 0.6116826482955514} \n",
      "Ensemble Models F1 Scores: {'Gradient Boosting': 0.6421174304489917, 'AdaBoost': 0.624575230812355, 'XGBoost': 0.6276340177982755}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score , precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to perform cross-validation for multiple ensemble methods\n",
    "def cross_val_score_ensemble(X, y, models, cv=10):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    model_accuracies = {name: [] for name in models.keys()}\n",
    "    model_precisions = {name: [] for name in models.keys()}\n",
    "    model_recalls = {name: [] for name in models.keys()}\n",
    "    model_f1_scores = {name: [] for name in models.keys()}\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            model_accuracies[name].append(accuracy_score(y_val, y_pred))\n",
    "            model_precisions[name].append(precision_score(y_val, y_pred))\n",
    "            model_recalls[name].append(recall_score(y_val, y_pred))\n",
    "            model_f1_scores[name].append(f1_score(y_val, y_pred))\n",
    "\n",
    "    \n",
    "    avg_accuracies = {name: np.mean(scores) for name, scores in model_accuracies.items()}\n",
    "    avg_precisions = {name: np.mean(scores) for name, scores in model_precisions.items()}\n",
    "    avg_recalls = {name: np.mean(scores) for name, scores in model_recalls.items()}\n",
    "    avg_f1_scores = {name: np.mean(scores) for name, scores in model_f1_scores.items()}\n",
    "\n",
    "    return [avg_accuracies, avg_precisions, avg_recalls, avg_f1_scores]\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation for ensemble methods\n",
    "ensemble_scores = cross_val_score_ensemble(X_scaled, y, models, cv=10)\n",
    "print(f'Ensemble Models Accuracies: {ensemble_scores[0]}'+ '\\n'+'Ensemble Models Precisions:',ensemble_scores[1],'\\n'+'Ensemble Models Recalls:',ensemble_scores[2],'\\n'+'Ensemble Models F1 Scores:',ensemble_scores[3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
