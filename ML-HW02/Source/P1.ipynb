{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"./datasets/housing.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "random_items = df.sample(n=10)\n",
    "random_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20433 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20433 non-null  float64\n",
      " 1   latitude            20433 non-null  float64\n",
      " 2   housing_median_age  20433 non-null  float64\n",
      " 3   total_rooms         20433 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20433 non-null  float64\n",
      " 6   households          20433 non-null  float64\n",
      " 7   median_income       20433 non-null  float64\n",
      " 8   median_house_value  20433 non-null  float64\n",
      " 9   ocean_proximity     20433 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20433, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True) #Missing value correction\\\\ Because the number of defected rows is small we decided to just remove it but we could according to their categroical train data on each and other numerical columns\n",
    "df[df.duplicated()]#check duplicated rows if exist. If it exists we can remove them\n",
    "\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25,16))\n",
    "aspect_ratio = 1.5 \n",
    "sns.pairplot(data=df,hue='ocean_proximity',aspect=aspect_ratio)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='ocean_proximity', y='median_house_value', data=df)\n",
    "plt.xlabel('Areas')\n",
    "plt.ylabel('Median House Value')\n",
    "plt.title(\"Median House Value-Ocean Proximity\")\n",
    "plt.show()\n",
    "\n",
    "df['ocean_proximity'].value_counts(normalize=True)\n",
    "\n",
    "grouped_1H_INLAND=df[df['ocean_proximity'].isin([\"<1H OCEAN\", \"INLAND\"])]\n",
    "\n",
    "grouped_OCEAN_NEAR_BAY_INLAND=df[df['ocean_proximity'].isin([\"NEAR OCEAN\", \"NEAR BAY\"])]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.kdeplot(data=grouped_1H_INLAND,x=\"median_house_value\",y=\"median_income\",hue=\"ocean_proximity\",fill=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.kdeplot(data=grouped_OCEAN_NEAR_BAY_INLAND,x=\"median_house_value\",y=\"median_income\",hue=\"ocean_proximity\",fill=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x =\"housing_median_age\" , hue = \"ocean_proximity\",multiple = \"dodge\",data=grouped_1H_INLAND)\n",
    "plt.xlabel('Areas')\n",
    "plt.title(\"Median House Age Ocean Proximity\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x =\"housing_median_age\" , hue = \"ocean_proximity\",multiple = \"dodge\",data=grouped_OCEAN_NEAR_BAY_INLAND)\n",
    "plt.xlabel('Areas')\n",
    "plt.title(\"Median House Age Ocean Proximity\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8),dpi=300)\n",
    "sns.set(style='dark')\n",
    "plt.title('Spatial Distribution Median House Values')\n",
    "norm =plt.Normalize(df['median_house_value'].min(),df['median_house_value'].max())\n",
    "ax=sns.scatterplot(x='longitude', y='latitude', hue='median_house_value',palette='RdYlBu', data=df)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdYlBu\", norm=norm)\n",
    "sm.set_array([])\n",
    "ax.get_legend().remove()  \n",
    "ax.figure.colorbar(sm,ax=ax.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_class in df.ocean_proximity.unique():\n",
    "    for column_name in df.columns.values[:-1]:\n",
    "        data=None\n",
    "        outliers=None\n",
    "        dff=df[df['ocean_proximity']==df_class]\n",
    "        data =dff[column_name].values\n",
    "\n",
    "        # Calculate Z-scores\n",
    "        z_scores = (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "        # Define threshold for outliers\n",
    "        threshold = 5\n",
    "\n",
    "        # Find outliers\n",
    "        outliers = np.where(np.abs(z_scores) > threshold)[0]\n",
    "        print(outliers)\n",
    "        print(data)\n",
    "\n",
    "        # Remove outliers\n",
    "        data_cleaned = np.delete(data, outliers)\n",
    "\n",
    "        # Plot data points\n",
    "        plt.scatter(dff.index, data, color='blue', label='All Data')\n",
    "        plt.scatter(dff.index[outliers], data[outliers], color='red', label='Outliers')\n",
    "        #plt.scatter(dff.index.drop(outliers), data_cleaned, color='green', label='Non-Outliers')\n",
    "\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Data Value')\n",
    "        plt.title('Outlier Removal and Visualization '+column_name+\"category: \"+df_class)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "\n",
    "df['ocean_proximity_id'] = LabelEncoder().fit_transform(df['ocean_proximity'])\n",
    "X = data.drop(['median_house_value','ocean_proximity'], axis=1)\n",
    "Y = data['median_house_value']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.values)\n",
    "Y_scaled = scaler.fit_transform(Y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_train, X_text, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "degrees = np.arange(8)\n",
    "mse_scores = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = Pipeline(steps=[\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    scores = cross_val_score(model, X_scaled, Y_scaled, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(scores)\n",
    "    mse_scores.append(-np.mean(scores))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(degrees, mse_scores, marker='o')\n",
    "plt.title('Degree vs. MSE')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n",
    "\n",
    "best_degree = degrees[np.argmin(mse_scores)]\n",
    "\n",
    "# Step f: Train the final model with the best degree and report MSE and R2 on the test data\n",
    "final_model = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=best_degree)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Final Model Performance:\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ocean_proximity_id'] = LabelEncoder().fit_transform(df['ocean_proximity'])\n",
    "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
    "df['population_per_household'] = df['population'] / df['households']\n",
    "\n",
    "X = df.drop(columns=['median_house_value','ocean_proximity','total_rooms','population','households'] )\n",
    "Y = df['median_house_value']\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y= StandardScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "Y_scaled = scaler_y.fit_transform(Y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "degrees = np.arange(8)\n",
    "mse_scores = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = Pipeline(steps=[\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    scores = cross_val_score(model, X_scaled, Y_scaled, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(scores)\n",
    "    mse_scores.append(-np.mean(scores))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(degrees, mse_scores, marker='o')\n",
    "plt.title('Degree vs. MSE')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n",
    "\n",
    "best_degree = degrees[np.argmin(mse_scores)]\n",
    "\n",
    "# Step f: Train the final model with the best degree and report MSE and R2 on the test data\n",
    "final_model = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=best_degree)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Final Model Performance:\",best_degree)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
